{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from unifier.models.vlm_src import load_mrm, load_gloria, load_mgca, load_medklip, load_medclip_resnet50, load_medclip_vit, load_refers, load_mflag, load_ptunifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_refers(\"/home/faith/unified-framework/ckpt/pretrained/REFERS.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForwardCaptioningModel(\n",
       "  (visual): ViTBackbone(\n",
       "    (vit): VisionTransformer(\n",
       "      (transformer): Transformer(\n",
       "        (embeddings): Embeddings(\n",
       "          (patch_embeddings): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): Encoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x Block(\n",
       "              (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "              (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "              (ffn): Mlp(\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (attn): Attention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "                (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (encoder_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fusion): fusion(\n",
       "    (fc1): Linear(in_features=2304, out_features=1, bias=True)\n",
       "    (fc2): Linear(in_features=2304, out_features=1, bias=True)\n",
       "    (fc3): Linear(in_features=2304, out_features=1, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (contrastive_bert): TextEncoder(\n",
       "    (text_encoder): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=2304, bias=True)\n",
       "  )\n",
       "  (textual): TransformerTextualHead(\n",
       "    (visual_projection): Linear(in_features=768, out_features=1024, bias=True)\n",
       "    (embedding): WordAndPositionalEmbedding(\n",
       "      (words): Embedding(10000, 1024, padding_idx=0)\n",
       "      (positions): Embedding(100, 1024)\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-08, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output): Linear(in_features=1024, out_features=10000, bias=True)\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       "  (infoNCE): LossesOfConVIRT()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unified-framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
