{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unifier.models.vlm_src import load_mrm, load_gloria, load_mgca, load_medklip, load_medclip_resnet50, load_medclip_vit, load_refers, load_mflag, load_ptunifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - METER - No observers have been added to this run\n",
      "INFO - METER - Running command 'main'\n",
      "INFO - METER - Started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73838e33e104e849943e79130be48f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b369b3f5f70b49cc94a8199bdb14f0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64e560d77094d798c648faa802bf8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30333229e4b34f1fba18202affb1d12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b2be026ce24b1791ef5d3be5ab7e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - METER - Failed after 0:00:17!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PTUnifierTransformerSS:\n\tsize mismatch for vision_encoder.visual.conv1.weight: copying a param with shape torch.Size([768, 3, 16, 16]) from checkpoint, the shape in current model is torch.Size([768, 3, 32, 32]).\n\tsize mismatch for language_encoder.embeddings.word_embeddings.weight: copying a param with shape torch.Size([50265, 768]) from checkpoint, the shape in current model is torch.Size([30522, 768]).\n\tsize mismatch for language_encoder.embeddings.position_embeddings.weight: copying a param with shape torch.Size([514, 768]) from checkpoint, the shape in current model is torch.Size([512, 768]).\n\tsize mismatch for language_encoder.embeddings.token_type_embeddings.weight: copying a param with shape torch.Size([1, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for mlm_head.bias: copying a param with shape torch.Size([50265]) from checkpoint, the shape in current model is torch.Size([30522]).\n\tsize mismatch for mlm_head.decoder.weight: copying a param with shape torch.Size([50265, 768]) from checkpoint, the shape in current model is torch.Size([30522, 768]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/faith/unified-framework/demo_notebooks/vision_language_models.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.9.10.130/home/faith/unified-framework/demo_notebooks/vision_language_models.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m load_ptunifier(\u001b[39m\"\u001b[39;49m\u001b[39m/home/faith/unified-framework/ckpt/pretrained/PTUnifier.ckpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/unified-framework/unifier/models/vlm_src/PTUnifier/builder.py:15\u001b[0m, in \u001b[0;36mload_ptunifier\u001b[0;34m(ckpt, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_ptunifier\u001b[39m(ckpt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     14\u001b[0m     \u001b[39m# override experiments config\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     model \u001b[39m=\u001b[39m ex\u001b[39m.\u001b[39;49mrun(config_updates\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mload_path\u001b[39;49m\u001b[39m'\u001b[39;49m: ckpt, \u001b[39m'\u001b[39;49m\u001b[39mpseudo_vision_token_pool_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m2048\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m                                    \u001b[39m'\u001b[39;49m\u001b[39mpseudo_langauge_token_pool_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m2048\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs})\n\u001b[1;32m     17\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/unified-framework/lib/python3.11/site-packages/sacred/experiment.py:276\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self, command_name, config_updates, named_configs, info, meta_info, options)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39mRun the main function of the experiment or a given command.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39mThe Run object corresponding to the finished run.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    273\u001b[0m run \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_run(\n\u001b[1;32m    274\u001b[0m     command_name, config_updates, named_configs, info, meta_info, options\n\u001b[1;32m    275\u001b[0m )\n\u001b[0;32m--> 276\u001b[0m run()\n\u001b[1;32m    277\u001b[0m \u001b[39mreturn\u001b[39;00m run\n",
      "File \u001b[0;32m~/miniconda3/envs/unified-framework/lib/python3.11/site-packages/sacred/run.py:238\u001b[0m, in \u001b[0;36mRun.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_heartbeat()\n\u001b[1;32m    237\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_pre_run_hooks()\n\u001b[0;32m--> 238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmain_function(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    239\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_post_run_hooks()\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/unified-framework/lib/python3.11/site-packages/sacred/config/captured_function.py:42\u001b[0m, in \u001b[0;36mcaptured_function\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m# =================== run actual function =================================\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mwith\u001b[39;00m ConfigError\u001b[39m.\u001b[39mtrack(wrapped\u001b[39m.\u001b[39mconfig, wrapped\u001b[39m.\u001b[39mprefix):\n\u001b[0;32m---> 42\u001b[0m     result \u001b[39m=\u001b[39m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     43\u001b[0m \u001b[39m# =========================================================================\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m wrapped\u001b[39m.\u001b[39mlogger \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/unified-framework/unifier/models/vlm_src/PTUnifier/builder.py:9\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(_config)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m@ex\u001b[39m\u001b[39m.\u001b[39mmain\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m(_config):\n\u001b[1;32m      8\u001b[0m     _config \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(_config)\n\u001b[0;32m----> 9\u001b[0m     model \u001b[39m=\u001b[39m PTUnifierTransformerSS(_config)\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/unified-framework/unifier/models/vlm_src/PTUnifier/models/ptunifier_module.py:98\u001b[0m, in \u001b[0;36mPTUnifierTransformerSS.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     94\u001b[0m     state_dict \u001b[39m=\u001b[39m ckpt[\u001b[39m\"\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     95\u001b[0m     state_dict \u001b[39m=\u001b[39m adapt_position_encoding(state_dict,\n\u001b[1;32m     96\u001b[0m                                          after\u001b[39m=\u001b[39mresolution_after,\n\u001b[1;32m     97\u001b[0m                                          patch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mpatch_size\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_state_dict(state_dict, strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     99\u001b[0m \u001b[39m# == End  : 3. Load Models ==\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[39m# == 4. Build Heads For Downstream Tasks ==\u001b[39;00m\n\u001b[1;32m    102\u001b[0m hs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mhidden_size\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/unified-framework/lib/python3.11/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PTUnifierTransformerSS:\n\tsize mismatch for vision_encoder.visual.conv1.weight: copying a param with shape torch.Size([768, 3, 16, 16]) from checkpoint, the shape in current model is torch.Size([768, 3, 32, 32]).\n\tsize mismatch for language_encoder.embeddings.word_embeddings.weight: copying a param with shape torch.Size([50265, 768]) from checkpoint, the shape in current model is torch.Size([30522, 768]).\n\tsize mismatch for language_encoder.embeddings.position_embeddings.weight: copying a param with shape torch.Size([514, 768]) from checkpoint, the shape in current model is torch.Size([512, 768]).\n\tsize mismatch for language_encoder.embeddings.token_type_embeddings.weight: copying a param with shape torch.Size([1, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for mlm_head.bias: copying a param with shape torch.Size([50265]) from checkpoint, the shape in current model is torch.Size([30522]).\n\tsize mismatch for mlm_head.decoder.weight: copying a param with shape torch.Size([50265, 768]) from checkpoint, the shape in current model is torch.Size([30522, 768])."
     ]
    }
   ],
   "source": [
    "model = load_ptunifier(\"/home/faith/unified-framework/ckpt/pretrained/PTUnifier.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unified-framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
