name: mvqa
ckpt_dir: ckpt

dataset:
  proto: Med_VQA_2021
  imgpath: /home/faith/MVLM/image_clef/imageclef-vqa-images-512

transforms:
  type: VQATransforms

model:
  proto: MVQA

  cnn:
    proto: VisualEncoder
    backbone: resnet50
    pretrained: /home/faith/unified-framework/ckpt/chexpert_resnet50.ckpt
    prefix: gloria.img_encoder.model.
    output_layer: layer4 # do not return fc layer
    dropout_out: 0.0
    permute: batch_first
    freeze: False

  adapter:
    input_size: 2048
    output_size: 768

  transformer:
    hidden_size: 768
    intermediate_size: 2048
    num_hidden_layers: 12
    num_attention_heads: 8
    attention_probs_dropout_prob: 0.1
    hidden_dropout_prob: 0.1
    hidden_act: gelu
    initializer_range: 0.02
    layer_norm_eps: 1.e-12

  classifier:
    proto: Classifier
    input_size: 768
    num_classes: 330 # MedVQA-2021 label size
    dropout: 0.

  loss:
    proto: LabelSmoothingCrossEntropy

trainer:
  optimizer: Adam
  optim_params:
    lr: 0.00005
    weight_decay: 5e-4
  batch_size: 32
  lr_decay: ReduceLROnPlateau
  lr_decay_params:
    factor: 0.5
    patience: 1
    min_lr: 0.000001
    threshold: 0.01
    threshold_mode: abs
  epochs: 99
  early_stop: 10
  eval_start: 0
  early_stop_metric: accuracy

validator:
  batch_size: 16
  metrics: [accuracy]
  splits: [valid]