name: gloria_mimic
ckpt_dir: ckpt

dataset:
  proto: MIMIC_Dataset
  imgpath: /home/faith/MVLM/mimic_512/files
  metacsvpath: /home/faith/MVLM/mimic_512/mimic-cxr-2.0.0-metadata.csv
  csvpath: USE_INCLUDED_FILE
  views: ["PA", "AP"]
  section: both
  tokenizer: emilyalsentzer/Bio_ClinicalBERT
  max_words: 128

transforms: 
  type: DataTransforms 
  options:
    resize: 256
    crop_size: 224

model:
  proto: GLoRIA
  forward_batch_size: 12
  encoder:
    proto: emilyalsentzer/Bio_ClinicalBERT
    last_n_layers: 4

  cnn:
    proto: VisualEncoder
    backbone: resnet50
    output_layer: avgpool
    dropout_out: 0.0
    permute: batch_first
    freeze: False

  visual_embedder:
    interm_feature_dim: 1024
    feature_dim: 2048

  loss:
    local_loss_weight: 1.0
    global_loss_weight: 1.0
    temp1: 4.0
    temp2: 5.0
    temp3: 10.0

trainer:
  optimizer: Adam
  optim_params:
    lr: 0.0001
  batch_size: 48
  lr_decay: ReduceLROnPlateau
  lr_decay_params:
    factor: 0.8
    patience: 5
    min_lr: 0.000001
    threshold: 0.01
    threshold_mode: abs
  epochs: 99
  early_stop: 20
  eval_start: 0
  early_stop_metric: validation_loss

validator:
  batch_size: 48
  splits: [valid]