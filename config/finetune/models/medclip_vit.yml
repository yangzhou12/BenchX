name: medclip_vit

model:
  cnn:
    proto: VisualEncoder
    backbone: hfpretrained
    encoder:
      proto: microsoft/swin-tiny-patch4-window7-224
      pretrained: /home/faith/unified-framework/ckpt/pretrained/MedCLIP.bin
      prefix: vision_model.model.
    dropout_out: 0.0
    permute: no_permute
    freeze: False

    #####  Uncomment below for zero-shot and cls  #####
    # visual_projection: 
    #   layer: >
    #     nn.Linear(768, 512, bias=False)
    #   prefix: visual_model.projection_head.

  fusion: # for MMVQA
    input_image_embed_size: 768

  transformer: # for RRG
    d_vf: 768

  classifier: # for CLS
    input_size: 768